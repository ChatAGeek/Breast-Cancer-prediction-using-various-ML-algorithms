# -*- coding: utf-8 -*-
"""Coursework AI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VI5lvnTTPKd11pZiq5LxlcWcdFGcabUI
"""

import pandas as pd
from google.colab import files
from google.colab import drive
import numpy as np
import seaborn as sns
import plotly.express as px
import plotly.graph_objs as go
from sklearn.model_selection import cross_val_score
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold, cross_val_score
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn import metrics
import warnings
import io

uploaded = files.upload()
data = pd.read_csv(io.BytesIO(uploaded['heart.csv']))

data.info()
#There are no null values

#Exploring the data
data.describe()
#We don't observe any noticeable difference in the data using the describe function.

#identify duplicate rows
duplicateRows = data[data.duplicated()]

#view duplicate rows
duplicateRows

data.drop_duplicates(inplace=True)
data.describe()

#Renaming columns
data = data.rename(columns={'age': 'Age', 'sex': 'Sex', 'cp': 'ChestPain', 'trestbps':'RestingBP','chol':'Cholesterol'
                       ,'fbs':'FastingBS','restecg':'RestingECG', 'thalach': 'Max HR','exang':'ExerciseAngina',
                        'oldpeak': 'Oldpeak','slope':'ST_Slope', 'ca':'NumberOfVessel', 'thal':'Thal','target':'HeartDisease'})


#data exploration and cleansing
data.isnull().sum()
#There are no null values

pd.crosstab(data.Age,data.HeartDisease).plot(kind="bar",figsize=(20,6))
plt.title('Heart Disease Frequency for Ages')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

# Boxplot of Maximum Heart rate agaisnt heart disease
sns.boxplot(x='HeartDisease', y='Max HR', data=data)
plt.xlabel('Heart Disease')
plt.ylabel('Max HR')
plt.title('Distribution of Max HR by Heart Disease')
plt.show()

#Data imbalance check

labels=["Healthy","Heart Disease"]

healthy_or_not = data['HeartDisease'].value_counts().tolist()
values = [healthy_or_not[0], healthy_or_not[1]]

fig = go.Figure(data=[go.Pie(labels=labels, values=data['HeartDisease'].value_counts())])
fig.update_traces(marker=dict(colors=["green", "maroon"]))

fig.show()

#We can see that the data is quite well balanced so we don't need to take advantage of undersampling or oversampling techniques.

# Checking correlation between features
fig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches
correlation_before_outliers = data.corr() 
sns.heatmap(data=correlation_before_outliers,cmap="Accent", annot=True,linewidths=.5, ax=ax)

# Identifying numerical and categorical columns
numerical_cols = list(data.loc[:,['Age', 'RestingBP', 'Cholesterol', 'Max HR', 'Oldpeak']])
categorical_cols = list(data.loc[:,['Sex', 'ChestPain', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']])

#Check for outliers using  boxplots

def boxplots_custom(dataset, columns_list, rows, cols, suptitle):
    fig, axs = plt.subplots(rows, cols, sharey=True, figsize=(13,5))
    fig.suptitle(suptitle,y=1, size=25)
    axs = axs.flatten()
    for i, data in enumerate(columns_list):
        sns.boxplot(data=dataset[data], orient='h', ax=axs[i])
        axs[i].set_title(data + ', skewness is: '+str(round(dataset[data].skew(axis = 0, skipna = True),2)))
        
boxplots_custom(dataset=data, columns_list=numerical_cols, rows=2, cols=3, suptitle='Boxplots for each variable')
plt.tight_layout()
#We can observe outliers on the dataset

#Showing percentage of outliers

# Store the initial total number of entries
total_entries = data.shape[0]

# Create an empty DataFrame to store the results
results_df = pd.DataFrame(columns=["Column", "Number of outliers", "Percentage of outliers"])

# Loop over each numeric column in the DataFrame
for col in data.select_dtypes(include=['number']).columns:
    # Compute the first and third quartiles
    q1 = data[col].quantile(0.25)
    q3 = data[col].quantile(0.75)
    
    # Compute the interquartile range
    iqr = q3 - q1
    
    # Compute the outlier fences
    fence_low = q1 - 1.5 * iqr
    fence_high = q3 + 1.5 * iqr
    
    # Compute the number of outliers in this column
    num_outliers = np.sum((data[col] < fence_low) | (data[col] > fence_high))
    
    # Compute the percentage of outliers in this column
    percent_outliers = num_outliers / total_entries * 100
    
   # Add the results for this column to the DataFrame
    results_df = results_df.append({
        "Column": col,
        "Number of outliers": num_outliers,
        "Percentage of outliers": percent_outliers
    }, ignore_index=True)

# Display the results DataFrame as a grid
display(results_df)

#Drop the outliers

outliers = data.shape[0]

# Loop over each numerical column in the DataFrame
for col in data.select_dtypes(include=['number']).columns:
     
    # Compute the first and third quartiles
    q1 = data[col].quantile(0.25)
    q3 = data[col].quantile(0.75)
    
    # Compute the interquartile range
    iqr = q3 - q1
    
    # Compute the Tukey fences
    fence_low = q1 - 1.5 * iqr
    fence_high = q3 + 1.5 * iqr
    
    
    # Identify the rows with values outside of the lower and upper bounds for this column
    outliers = (data[col] < fence_low) | (data[col] > fence_high)

    # Drop the outliers from the DataFrame
    data = data[~outliers]
    
    # Print the results for this column
    print("Column:", col)
    print("Total entries:", total_entries)
    print("Number of outliers:", num_outliers)
    print("Percentage of outliers:", percent_outliers,"%")
    print()

# Reset the index of the DataFrame
data = data.reset_index(drop=True)
data.info()

# Checking correlation after dropping outliers
data.corr()

ig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches
correlation_after_outliers = data.corr()
sns.heatmap(data=correlation_after_outliers,cmap="Accent", annot=True,linewidths=.5, ax=ax)

#No high correlation between features

#[11] A. Nair, “Targeting Multicollinearity With Python,” Medium, Dec. 06, 2021. https://towardsdatascience.com/targeting-multicollinearity-with-python-3bd3b4088d0b (accessed Mar. 09, 2023).

#Scaling to find multicollinearity in the dataset using Variance Inflation Factor (VIF) 

from statsmodels.stats.outliers_influence import variance_inflation_factor

# Separate the target variable from the feature variables
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Scale the feature variables to have a mean of 0 and a standard deviation of 1
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Calculate the VIF scores for each feature variable
vif = pd.DataFrame()
vif['Features'] = X.columns
vif['VIF'] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]

# Print the VIF scores
print(vif)

# Remove the feature variable with the highest VIF score and recalculate the VIF scores
while vif['VIF'].max() > 5:
    # Remove the feature variable with the highest VIF score
    max_vif_idx = vif['VIF'].idxmax()
    vif.drop(max_vif_idx, axis=0, inplace=True)
    
    # Recalculate the VIF scores
    X_scaled = np.delete(X_scaled, max_vif_idx, axis=1)
    vif['VIF'] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]

# Print the selected feature variables
print(vif['Features'])

# [12]“Generate classification report and confusion matrix in Python -,” DeZyre. https://www.projectpro.io/recipes/generate-classification-report-and-confusion-matrix-in-python

#Logistic Regression with Train test split : 80:20 split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Separate features from target
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a logistic regression model
clf_model = LogisticRegression()
clf_model.fit(X_train, y_train)

# Evaluate the model on the testing set
y_pred = clf_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:\n", confusion_mat)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Plotting the confusion matrix
sns.heatmap(confusion_mat, annot=True, cmap="Blues", fmt="d")

#Logistic Regression with cross validation
# Separate features from target
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Train a logistic regression model
clf_model = LogisticRegression()

# Evaluate the model using cross-validation
cv_scores = cross_val_score(clf_model, X, y, cv=10)
print(f"Cross-validation scores: {cv_scores}")
print(f"Mean CV score: {cv_scores.mean():.4f}")
print(f"Standard deviation: {cv_scores.std():.4f}")

# Fit the model on the entire dataset
clf_model.fit(X, y)

# Predict on the entire dataset
y_pred = clf_model.predict(X)
accuracy = accuracy_score(y, y_pred)
precision = precision_score(y, y_pred)
recall = recall_score(y, y_pred)
f1 = f1_score(y, y_pred)
confusion_mat = confusion_matrix(y, y_pred)

print("\nConfusion Matrix:\n", confusion_mat)
print("\nClassification Report:\n", classification_report(y, y_pred))
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

# Using hyperparaters to train the Logistic regression model
warnings.filterwarnings("ignore")
X = data.drop('HeartDisease', axis=1) # separate features from target
y = data['HeartDisease']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

clf_model2 = LogisticRegression()

# Define the hyperparameters to tune
hyperparameters = {
    'penalty': ['l1', 'l2'],
    'C': [0.1, 1, 10, 100],
    'solver': ['lbfgs', 'liblinear', 'saga']
}

# Use GridSearchCV to find the optimal hyperparameters
kfold = KFold(n_splits=10, shuffle=True, random_state=42)
grid_search_lr = GridSearchCV(clf_model2, hyperparameters, cv=kfold, scoring='accuracy')
grid_search_lr.fit(X_train, y_train)
best_params = grid_search_lr.best_params_

print('Best hyperparameters:', grid_search_lr.best_params_)
print('Best cross-validation score:', grid_search_lr.best_score_)

# Train the logistic regression model with the best hyperparameters on training set
best_lr = LogisticRegression(random_state=42, **best_params)
best_lr.fit(X_train, y_train)

# Make predictions on new data
y_pred = best_lr.predict(X_test)

# evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)
cv_scores = cross_val_score(best_lr, X, y, cv=10)

# Calculate and print the accuracy score on the test data
test_accuracy = metrics.accuracy_score(y_test, y_pred)
print("Test accuracy:", test_accuracy)


print("\nConfusion Matrix:\n", confusion_mat)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

#Using Random Forest Algorithm
warnings.filterwarnings("ignore")
X = data.drop('HeartDisease', axis = 1)
y = data['HeartDisease']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

rfc = RandomForestClassifier()

hyperparameters = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]

kfold = KFold(n_splits=10, shuffle=True, random_state=42)
grid_search_rfc = GridSearchCV(rfc, hyperparameters, cv = kfold, scoring='accuracy')
grid_search_rfc.fit(X_train, y_train)
print(grid_search_rfc.best_params_)
print(grid_search_rfc.best_score_)

# Train the random forest classifier on the best hyperparameters
best_rfc = RandomForestClassifier(**grid_search_rfc.best_params_, random_state=42)
best_rfc.fit(X_train, y_train)

# Test the random forest classifier on the testing set
y_pred = best_rfc.predict(X_test)

# evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)
cv_scores = cross_val_score(best_lr, X, y, cv=10)

# Calculate and print the accuracy score on the test data
test_accuracy = metrics.accuracy_score(y_test, y_pred)
print("Test accuracy:", test_accuracy)

print("\nConfusion Matrix:\n", confusion_mat)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")

#Using Neural Networks algorithm using Sequential or RNN
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn import metrics
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense

# Split data into features and target variable
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model architecture
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model with binary cross-entropy loss and Adam optimizer
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model on the training data
model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split=0.2)

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Make predictions on the test data
y_pred = (model.predict(X_test) > 0.5).astype(int)

# evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)
cv_scores = cross_val_score(best_lr, X, y, cv=10)

# Calculate and print the accuracy score on the test data
test_accuracy = metrics.accuracy_score(y_test, y_pred)
print("Test accuracy:", test_accuracy)

# Calculate and print the classification report and confusion matrix on the test data
print("Classification report:\n", metrics.classification_report(y_test, y_pred))
print("Confusion matrix:\n", metrics.confusion_matrix(y_test, y_pred))

#Using Neural Networks algorithm using Multi-Layer Perceptron (MLP) binary classification model
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn import metrics
import pandas as pd
from keras.layers import Input, Dense
from keras.models import Model

# Split data into features and target variable
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model architecture
inputs = Input(shape=(X_train.shape[1],))
x = Dense(64, activation='relu')(inputs)
x = Dense(32, activation='relu')(x)
outputs = Dense(1, activation='sigmoid')(x)

model = Model(inputs=inputs, outputs=outputs)

# Compile the model with binary cross-entropy loss and Adam optimizer
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model on the training data
model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)

# Evaluate the model on the test data
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test accuracy:', test_acc)

# Make predictions on the test data
y_pred = (model.predict(X_test) > 0.5).astype(int)

# evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
confusion_mat = confusion_matrix(y_test, y_pred)
cv_scores = cross_val_score(best_lr, X, y, cv=10)

# Calculate and print the accuracy score on the test data
test_accuracy = metrics.accuracy_score(y_test, y_pred)
print("Test accuracy:", test_accuracy)
print("\nConfusion Matrix:\n", confusion_mat)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")